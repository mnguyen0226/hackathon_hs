# Tutorial 6: You vs Trained DQN RL Agent with Stable Baselines On Pokemon Showdown

This tutorial is inspired from [Reinforcement learning with the OpenAI Gym wrapper](https://poke-env.readthedocs.io/en/latest/rl_with_open_ai_gym_wrapper.html) example from Poke-env. We will show:
- How to fight against your trained DQN Agent integrated with Stable Baselines framework.

**Note:** You will need to create two Pokemon-Showdown account for you and your bot in this tutorial since you will fight on global server of Pokemon Showdown. You will need two laptops / machines or two browsers (one private, one public).

**Note:** The code for this tutorial can be found [here](https://github.com/mnguyen0226/hackathon_hs/tree/main/src/tutorials/tutorial_six).

Assuming that you have already got the installation and was able to put up your local server like this:

```
RESTORE CHATROOM: lobby
RESTORE CHATROOM: staff
Worker 1 now listening on 0.0.0.0:8000
Test your server at http://localhost:8000
```
**Note:** Make sure to keep your local server runs at all time.


Next, [create](https://www.quora.com/How-do-you-sign-up-for-Pokemon-Showdown#:~:text=Go%20to%20Showdown!,the%20picture%20and%20its%20done!) two Pokemon Showdown accounts, one for you and one for your bot. In this example, "mnguyen" is the account for user and "minheapolis_bot" is the account for the pokebot. After create your accounts, log your accounts in two browser on [Pokemon Showdown global server](https://pokemonshowdown.com/).


Next, generate, train, and save the SimpleRLPlayer agent similar to [Tutorial 5](https://github.com/mnguyen0226/hackathon_hs/blob/main/src/tutorials/tutorial_five/t5.md). 

Next, write a script to create a player for your bot, link it with Pokemon Showdown "minheapolis_bot" account. This script is slightly similar to SimpleRLPlayer() class in Tutorial 5 but with the additional of _action_to_move() and choose_move() functions which enable the trained agent to automatically choose best action in Pokemon Showdown:

```
trained_model = DQN.load(
    "/home/mnguyen/Documents/summer2021/pokemon/hackathon_hs/src/tutorials/tutorial_six/dqn_sb_agent"
)

class TrainedRLPlayer(Gen8EnvSinglePlayer):
    observation_space = Box(low=-10, high=10, shape=(10,))
    action_space = Discrete(22)

    def getThisPlayer(self):
        """Get the current RL agent"""
        return self

    def __init__(self, *args, **kwargs):
        """Initialize agent"""
        Gen8EnvSinglePlayer.__init__(self, *args, **kwargs)
        self.model = trained_model

    def embed_battle(self, battle):
        """Embed Player to battles and return info from the Pokemon Showdown environment
        Parameter
        ----------
        battle:
            Max damage player's turn in the battle
        Return
        ----------
        list of [4 moves, damaging values of each moves, number of pokemons of player, number of pokemons of opponent]
        """
        # -1 indicates that the move does not have a base power
        # or is not available
        moves_base_power = -np.ones(4)
        moves_dmg_multiplier = np.ones(4)
        for i, move in enumerate(battle.available_moves):
            moves_base_power[i] = (
                move.base_power / 100
            )  # Simple rescaling to facilitate learning
            if move.type:
                moves_dmg_multiplier[i] = move.type.damage_multiplier(
                    battle.opponent_active_pokemon.type_1,
                    battle.opponent_active_pokemon.type_2,
                )

        # We count how many pokemons have not fainted in each team
        remaining_mon_team = (
            len([mon for mon in battle.team.values() if mon.fainted]) / 6
        )
        remaining_mon_opponent = (
            len([mon for mon in battle.opponent_team.values() if mon.fainted]) / 6
        )

        # Final vector with 10 components
        return np.concatenate(
            [
                moves_base_power,
                moves_dmg_multiplier,
                [remaining_mon_team, remaining_mon_opponent],
            ]
        )

    def compute_reward(self, battle) -> float:
        """Compute rewards for each action taken of player in the battle
        Parameter
        ----------
        battle:
            Max damage player's turn in the battle
        Return
        ---------
        float value of the rewards return from the environment
        """
        return self.reward_computing_helper(
            battle, fainted_value=2, hp_value=1, victory_value=30
        )

    def _action_to_move(self, action, battle):

        """Converts actions to move orders.
        The conversion is done as follows:
        0 <= action < 4:
        The actionth available move in battle.available_moves is executed.
        4 <= action < 8:
        The action - 4th available move in battle.available_moves is executed, with
        z-move.
        8 <= action < 12:
        The action - 8th available move in battle.available_moves is executed, with
        mega-evolution.
        12 <= action < 18
        The action - 12th available switch in battle.available_switches is executed.
        If the proposed action is illegal, a random legal move is performed.
        :param action: The action to convert.
        :type action: int
        :param battle: The battle in which to act.
        :type battle: Battle
        :return: the order to send to the server.
        :rtype: str
        """
        if (
                action < 4
                and action < len(battle.available_moves)
                and not battle.force_switch
        ):
            return self.create_order(battle.available_moves[action])
        elif (
                not battle.force_switch
                and battle.can_z_move
                and 0 <= action - 4 < len(battle.active_pokemon.available_z_moves)
        ):
            return self.create_order(
                battle.active_pokemon.available_z_moves[action - 4], z_move=True
            )
        elif (
                battle.can_mega_evolve
                and 0 <= action - 8 < len(battle.available_moves)
                and not battle.force_switch
        ):
            return self.create_order(battle.available_moves[action - 8], mega=True)
        elif (
                battle.can_dynamax
                and 0 <= action - 12 < len(battle.available_moves)
                and not battle.force_switch
        ):
            return self.create_order(battle.available_moves[action - 12], dynamax=True)
        elif 0 <= action - 16 < len(battle.available_switches):
            return self.create_order(battle.available_switches[action - 16])
        else:
            return self.choose_random_move(battle)

    def choose_move(self, battle):
        """Choose move automatically
        Parameter
        ----------
        battle:
            Max damage player's turn in the battle
        Return
        ----------
        Either best action or random action
        """
        if (battle.available_moves):
            observations = self.embed_battle(battle)
            action = self.model.predict(observations)[0] 
            return self._action_to_move(action, battle)
        else: 
            print("Random Move")
            return self.choose_random_move(battle)
```

Next, write a script to create a player for your bot, link it with Pokemon Showdown "minheapolis_bot" account, and challenge the "mnguyen" account:

```
async def main():
    # Create a TrainedRLPlayer
    simplerl_player = TrainedRLPlayer(
        player_configuration=PlayerConfiguration("minheapolis_bot", "heron_is_a_bird"),
        server_configuration=ShowdownServerConfiguration,
    )

    # Sending challenges to "your_username"
    await simplerl_player.send_challenges("mnguyen", n_challenges=1)

    # Accepting one challenge from any user
    await simplerl_player.accept_challenges(None, 1)

    # Accepting three challenges from "your_username"
    await simplerl_player.accept_challenges("mnguyen", 2)

    # Playing 5 games on the ladder
    await simplerl_player.ladder(5)

    # Print the rating of the player and tis opponent after each battle
    for battle in simplerl_player.battles.values():
        print(battle.rating, battle.opponent_rating)
```

Then, run your pokebot script, similar to [this](https://github.com/mnguyen0226/hackathon_hs/blob/main/src/tutorials/tutorial_six/load_script.py), on local terminal, you shoule see something like this:
```
2021-08-18 18:50:04,720 - minheapolis_bot - WARNING - Unhandled message: |queryresponse|debug|"1745258-1"

2021-08-18 18:50:04,720 - minheapolis_bot - WARNING - Unhandled message: |queryresponse|debug|"connect2"
2021-08-18 18:50:06,559 - minheapolis_bot - WARNING - Received pm: |pm|!minheapolis_bot|~|/error Due to spam from your internet provider, you can't challenge others right now. Logging into an account you've used a lot in the past will allow you to challenge.
2021-08-18 18:50:39,145 - minheapolis_bot - WARNING - Received pm: |pm|!mnguyen|!minheapolis_bot|/nonotify mnguyen accepted the challenge, starting &laquo;<a href="/battle-gen8randombattle-1399243812">battle-gen8randombattle-1399243812</a>&raquo;
```

Next, on your "minheapolis_bot" account on Pokemon Showdown global server, search for your "mnguyen" account and challenge it. Then, on your "mnguyen" account, accept the challenge.

**Tip:** If you were not able to "search name" or "challenge", refresh your Pokemon Showdown pages couple time then retry to "challenge".

On your pokebot "minheapolis_bot" account, you should see something like below. The bot will automatically pick actions to fight.
![alt text](https://github.com/mnguyen0226/hackathon_hs/blob/main/docs/imgs/t6_minheapolis_bot.png)

On your "mnguyen" account, you should see something like below. You will have to pick action and try to win against your bot.
![alt text](https://github.com/mnguyen0226/hackathon_hs/blob/main/docs/imgs/t6_mnguyen.PNG)

Lastly, just play and have fun! Congrats! You have completed this tutorial!
